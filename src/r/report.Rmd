---
title: "foo"
author: "Anonymous"
knit: (function(input_file, encoding) { 
      out_dir <- "../../build";
      rmarkdown::render(input_file,
                        encoding=encoding, 
                        output_file=file.path(dirname(input_file), out_dir, 'report.pdf')); })
output: 
  pdf_document: 
    toc: yes
    toc_depth: 1
urlcolor: blue
bibliography: "`r here::here('src/tex', 'ref.bib')`"
---

```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf.
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Formula One (F1) is the most prestigious auto racing league in the world. The number of drivers in this racing class is only 20, and those taking part could be considered "the best of the best". Given the fierce level of competition, every attribute of the driver could be considered important. An F1 driver must be at least 18 years of age, that is, the participating racers are all adults. It is a well-known fact that motor skills and reflexes of adults deteriorate with age. In this report we explore the relationship between the age and performance of F1 drivers through Bayesian analysis. In particular, we consider and compare three models: separate, pooled, and hierarchical. The models incorporate weakly priors, and related discussion of choices and sensitivity analysis is provided for each model separately. We further conduct posterior predictive analysis and finally provide a discussion on the models and potential future research.

# Data

Our analysis problem revolves around extracting posterior statistics yielding information about the relationship between a driver's age and performance. An example of such statistic would be the probability that the best age performance-wise lies within a certain range. The raw data is provided by the [@ergast]. For the purposes of our analysis, we conduct an number of preprocessing steps on this dataset. In particular, we consider the latest qualifying sessions where a driver and his teammate participated in. In F1, a qualifying session consists of three timed parts, called Q1, Q2, and Q3. From the latest session we first compute for each driver the difference between his time and the best time in that part, and further subtract from this the historical mean value of the time difference between a driver and his teammate in qualifyings. This yields a measure of the driver's performance with the mean baseline.

The same underlying data has been utilized by various authors. For example, [@nigro2021] examines how odds provided by a neural network model fit to a subset of the data fares against officially provided odds. Related to our analysis, the author notes that the age of the winning driver shows a decreasing linear trend. [@jain2020] on the other hand utilizes logistic regression with $F_1$ score to predict whether or not a driver manages to place on podium, i.e., to attain a top-three position. Similar to us, [@vankesteren2021] conducts a Bayesian analysis. The author models the skill of drivers considering factors including constructor advantages and seasonal constructor form. In contrast, our analysis is solely based on exploring whether or not a driver's age provides meaningful insight on his performance.

# Models

In this section we enumerate and describe the three models we attempt to fit to the data described previously. Let us first define some general prerequisites. Let $N$ denote the size of the dataset. Further, let $\mathcal{I} = \left\{1, 2, \dots, N\right\}$ denote the index set of the dataset, and $\mathcal{A} = \left\{18, 19, \dots, 43\right\}$ the set of driver ages present in the dataset. Now let $\text{age}(\cdot)$ be a mapping from $\mathcal{I}$ to $\mathcal{A}$ yielding the age of the sample at index $i \in \mathcal{I}$.

## Separate

The separate model is formally defined as follows:

$$
\begin{aligned}
t_i &\sim \mathrm{N}(\mu_{\text{age}(i)}, \sigma_{\text{age}(i)}), \\
\mu_{\text{age}(i)} &\sim \mathrm{N}(0,1), \\
\sigma_{\text{age}(i)} &\sim \mathrm{N}(0,1).
\end{aligned}
$$

The separate model effectively assumes the defining characteristics of the distribution for $t_i$ are different for each age group.

## Pooled

The pooled model is formally defined as follows:

$$
\begin{aligned}
t_i &\sim \mathrm{N}(\mu, \sigma), \\
\mu &\sim \mathrm{N}(0,1), \\
\sigma &\sim \mathrm{N}(0,1).
\end{aligned}
$$

The pooled model simply assumes the characteristics of the distribution generating $t_i$ are independent of driver age.

## Hierarchical

Finally, the hierarchical model is defined as follows:

$$
\begin{aligned}
t_i &\sim \mathrm{N}(\mu_{\text{age}(i)}, \sigma), \\
\mu_{\text{age}(i)} &\sim \mathrm{N}(\mu_{\text{unknown}}, \tau), \\
\mu_{\text{unknown}} &\sim \mathrm{N}(0, 1), \\
\tau &\sim \mathrm{N}(0, 1), \\
\sigma &\sim \mathrm{N}(0, 1).
\end{aligned}
$$

In the hierarchical model, the variance of the distribution describing $t_i$ is assumed the same for each age group. However, the mean of this distribution is assumed to be dependent on age. The parameters of the distribution yielding the mean of a particular age group are further sampled from the hyperpriors described above.

# Weakly Prior Choices

In this kind of setting, we make a common assumption that the posterior distribution for $t_i$ is of normal form. We refer to the data for prior information about the mean and variance of this distribution. We observe that the majority of time differences between drivers lie within the interval $[-2.5, 2.5]$, which gives rise to a weakly informative prior distribution for the mean of the distribution describing $t_i$ as $\mathrm{N}(0,1)$. Furthermore, it is evident that the differences between teammates is seldom over one second, which gives rise to a prior distribution for the variance of the distribution describing $t_i$ also as $\mathrm{N}(0,1)$. It turns out that the prior distributions are conjugate for the posterior distribution.

# Stan Code

TODO: Stan codes here

# Running the Stan Code

...

# Convergence Evaluation

...

# Posterior Predictive Checks

...

# Model Comparison

...

# Predictive Performance Assessment

...

# Prior Sensitivity Analysis

...

# Discussion

...

# Conclusions and Self-Reflections

...

# References